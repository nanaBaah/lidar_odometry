#!/usr/bin/env python3
# Developed by Xieyuanli Chen and Thomas LÃ¤be
# This file is covered by the LICENSE file in the root of this project.
# Brief: This script generate the overlap and orientation combined mapping file.

try:
    from utils import *
except:
    from utils import *


def com_overlap_yaw(scan_paths, poses, frame_idx, leg_output_width=360):
    """compute the overlap and yaw ground truth from the ground truth poses,
       which is used for OverlapNet training and testing.
       Args:
         scan_paths: paths of all raw LiDAR scans
         poses: ground-truth poses either given by the dataset or generated by SLAM or odometry
         frame_idx: the current frame index
       Returns:
         ground_truth_mapping: the ground truth overlap and yaw used for training OverlapNet,
                               where each row contains [current_frame_idx, reference_frame_idx, overlap, yaw]
    """
    # init ground truth overlap and yaw
    print('Start to compute ground truth overlap and yaw ...')
    overlaps = []

    yaw_idxs = []
    pitch_idxs = []
    roll_idxs = []

    x_idxs = []
    y_idxs = []
    z_idxs = []

    yaw_resolution = leg_output_width
    pitch_resolution = leg_output_width
    roll_resolution = leg_output_width

    x_resolution = leg_output_width
    y_resolution = leg_output_width
    z_resolution = leg_output_width

    # we calculate the ground truth for one given frame only
    # generate range projection for the given frame
    current_points = load_vertex(scan_paths[frame_idx])
    current_range, project_points, _, _ = range_projection(current_points)
    visible_points = project_points[current_range > 0]
    valid_num = len(visible_points)
    current_pose = poses[frame_idx]
    visible_points_world = current_pose.dot(visible_points.T).T

    for refrence_idx in range(len(scan_paths)):
        # generate range projection for the reference frame
        refrence_pose = poses[refrence_idx]
        points_reference = np.linalg.inv(refrence_pose).dot(visible_points_world.T).T
        reference_range, reference_points, _, _ = range_projection(points_reference)

        # calculate overlap
        overlap = np.count_nonzero(
            abs(reference_range[reference_range > 0] - current_range[reference_range > 0]) < 1) / valid_num
        overlaps.append(overlap)

        # calculate yaw angle
        relative_transform = np.linalg.inv(current_pose).dot(refrence_pose)
        relative_rotation = relative_transform[:3, :3]
        roll, pitch, yaw = euler_angles_from_rotation_matrix(relative_rotation)

        x, y, z = relative_transform[:3, -1]

        # discretize yaw angle and shift the 0 degree to the center to make the network easy to learn
        yaw_element_idx = int(- (yaw / np.pi) * yaw_resolution // 2 + yaw_resolution // 2)
        yaw_idxs.append(yaw_element_idx)

        roll_element_idx = int(- (roll / np.pi) * roll_resolution // 2 + roll_resolution // 2)
        roll_idxs.append(roll_element_idx)

        pitch_element_idx = int(- (pitch / np.pi) * pitch_resolution // 2 + pitch_resolution // 2)
        pitch_idxs.append(pitch_element_idx)

        x_idxs.append(x)
        y_idxs.append(y)
        z_idxs.append(z)

        # print('finished pair id: ', refrence_idx)

    # ground truth format: each row contains [current_frame_idx, reference_frame_idx, overlap, yaw]
    ground_truth_mapping = np.zeros((len(scan_paths), 9))
    ground_truth_mapping[:, 0] = np.ones(len(scan_paths)) * frame_idx
    ground_truth_mapping[:, 1] = np.arange(len(scan_paths))
    ground_truth_mapping[:, 2] = overlaps
    ground_truth_mapping[:, 3] = yaw_idxs
    ground_truth_mapping[:, 4] = roll_idxs
    ground_truth_mapping[:, 5] = pitch_idxs
    ground_truth_mapping[:, 6] = x_idxs
    ground_truth_mapping[:, 7] = y_idxs
    ground_truth_mapping[:, 8] = z_idxs

    print('Finish generating ground_truth_mapping!')

    return ground_truth_mapping
